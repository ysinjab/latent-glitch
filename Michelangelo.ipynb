{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysinjab/latent-glitch/blob/main/Michelangelo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation based and inspired on original paper https://arxiv.org/abs/1707.09557"
      ],
      "metadata": {
        "id": "sSLnAqTZjINe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RymAZtKeR0_G"
      },
      "source": [
        "# Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3S-jSc-dRq4t"
      },
      "outputs": [],
      "source": [
        "!pip install voxelfuse\n",
        "!pip install tensorflow-gan\n",
        "\n",
        "import os\n",
        "import scipy\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Conv3D, Conv3DTranspose, Activation, BatchNormalization, LeakyReLU, Flatten, Reshape, Dense, Dropout, UpSampling3D\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras import backend \n",
        "from tensorflow.keras.constraints import Constraint\n",
        "import tensorflow_gan as tfgan\n",
        "from google.colab import output\n",
        "from voxelfuse.voxel_model import VoxelModel\n",
        "from voxelfuse.mesh import Mesh\n",
        "from voxelfuse.primitives import generateMaterials\n",
        "\n",
        "output.clear()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plb05NWsR16O"
      },
      "source": [
        "# Generator & Discrimniator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g5gImxhOR_V1"
      },
      "outputs": [],
      "source": [
        "def make_Generator(kernel_size=5, strides=2, latent_dim=32):\n",
        "     model = Sequential()\n",
        "     model.add(Input(shape=(latent_dim,)))\n",
        "\n",
        "     model.add(Dense(units=2048, input_shape=(latent_dim,), use_bias=False))\n",
        "     model.add(BatchNormalization(momentum=0.9))\n",
        "     model.add(Reshape((2, 2, 2, 256)))\n",
        "     model.add(Activation('relu'))\n",
        "     model.add(Dropout(0.4))\n",
        "\n",
        "     model.add(UpSampling3D())\n",
        "     model.add(Conv3DTranspose(filters=512, kernel_size=kernel_size, padding='same', use_bias=False))\n",
        "     model.add(BatchNormalization(momentum=0.9))\n",
        "     model.add(Activation('relu'))\n",
        "\n",
        "     model.add(UpSampling3D())\n",
        "     model.add(Conv3DTranspose(filters=256, kernel_size=kernel_size, padding='same', use_bias=False))\n",
        "     model.add(BatchNormalization(momentum=0.9))\n",
        "     model.add(Activation('relu'))\n",
        "\n",
        "     model.add(UpSampling3D())\n",
        "     model.add(Conv3DTranspose(filters=128, kernel_size=kernel_size, padding='same', use_bias=False))\n",
        "     model.add(BatchNormalization(momentum=0.9))\n",
        "     model.add(Activation('relu'))\n",
        "\n",
        "     model.add(UpSampling3D())\n",
        "     model.add(Conv3DTranspose(filters=64, kernel_size=kernel_size, padding='same', use_bias=False))\n",
        "     model.add(BatchNormalization(momentum=0.9))\n",
        "     model.add(Activation('relu'))\n",
        "\n",
        "     model.add(UpSampling3D())\n",
        "     model.add(Conv3DTranspose(filters=1, kernel_size=kernel_size, padding='same', use_bias=False))\n",
        "     model.add(Activation('sigmoid'))\n",
        "\n",
        "     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cgFRHu9FSBLE"
      },
      "outputs": [],
      "source": [
        "def make_Discriminator(kernel_size=5, strides=2, im_dim=64):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(im_dim, im_dim, im_dim, 1)))\n",
        "    \n",
        "    model.add(Conv3D(filters=64, kernel_size=kernel_size, strides=strides, padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.35))\n",
        "\n",
        "    model.add(Conv3D(filters=128,kernel_size=kernel_size, strides=strides, padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.35))\n",
        "\n",
        "    model.add(Conv3D(filters=256,kernel_size=kernel_size, strides=strides, padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.35))\n",
        "\n",
        "    model.add(Conv3D(filters=512,kernel_size=kernel_size, strides=strides, padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.35))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHb82N9dSHVE"
      },
      "source": [
        "# Prepare training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUk7MYadSNKm",
        "outputId": "b3d78069-2f91-4c90-8f53-66a5cb8bcb93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1T9ZG0BKIFkotve7zvxbgPOicRQs1sreh\n",
            "To: /content/64.zip\n",
            "\r  0% 0.00/78.9k [00:00<?, ?B/s]\r100% 78.9k/78.9k [00:00<00:00, 29.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /content/datasets/meshes\n",
        "# https://drive.google.com/file/d//view?usp=sharing\n",
        "!gdown --id 1T9ZG0BKIFkotve7zvxbgPOicRQs1sreh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vtBqgT_3SSAC"
      },
      "outputs": [],
      "source": [
        "!unzip /content/64.zip -d  /content/datasets/meshes\n",
        "!rm /content/datasets/meshes/64/.DS_Store\n",
        "output.clear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JYbTfCW3SWHN"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/datasets/meshes/64/__MACOSX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XwnGqHiwSgwu"
      },
      "outputs": [],
      "source": [
        "training_data = []\n",
        "data_path = '/content/datasets/meshes/64'\n",
        "\n",
        "for filename in os.listdir(data_path):\n",
        "  voxel_model = np.load(f'{data_path}/{filename}', allow_pickle=True)['arr_0']\n",
        "  training_data.append(voxel_model)\n",
        "\n",
        "training_data = np.array(training_data).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKujT9GKSkGN",
        "outputId": "4ca93ed9-9f5e-4c70-d4bf-4733df976a8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW3k05dySmtq",
        "outputId": "1054606d-a16a-4796-f67f-ef7e8c9c0d3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "training_data[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtmzf2isSsCv"
      },
      "source": [
        "# Define functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DUDluDvdSucX"
      },
      "outputs": [],
      "source": [
        "def save_voxel(voxel_model, path):\n",
        "    model = VoxelModel(voxel_model)  \n",
        "    print('model = VoxelModel(voxel_model)  ')\n",
        "    mesh = Mesh.fromVoxelModel(model)\n",
        "    print('mesh = Mesh.fromVoxelModel(model)')\n",
        "    mesh.export(path)\n",
        "\n",
        "def gradient_penalty(real, fake, epsilon): \n",
        "    global discriminator\n",
        "    #mixed_images = real * epsilon + fake * (1 - epsilon)\n",
        "    mixed_images = fake + epsilon * (real - fake)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(mixed_images) \n",
        "        mixed_scores = discriminator(mixed_images)\n",
        "        \n",
        "\n",
        "    gradient = tape.gradient(mixed_scores, mixed_images)[0]\n",
        "    \n",
        "    gradient_norm = tf.norm(gradient)\n",
        "    penalty = tf.math.reduce_mean((gradient_norm - 1)**2)\n",
        "    return penalty\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    gen_loss = -1. * tf.math.reduce_mean(fake_output)\n",
        "    return gen_loss\n",
        "\n",
        "def discriminator_loss(real_output, fake_output, gradient_penalty):\n",
        "    c_lambda = 10\n",
        "    loss = tf.math.reduce_mean(fake_output) - tf.math.reduce_mean(real_output) + c_lambda * gradient_penalty\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB7YgQy6TCM1"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "n2jkF5WAT-cl"
      },
      "outputs": [],
      "source": [
        "discriminator = make_Discriminator()\n",
        "generator = make_Generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T81k-7OqT--j",
        "outputId": "dcbde7ff-9e12-4408-fe12-9fe0d52375b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 2048)              65536     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 2048)             8192      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 2, 2, 2, 256)      0         \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 2, 2, 2, 256)      0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 2, 2, 2, 256)      0         \n",
            "                                                                 \n",
            " up_sampling3d_5 (UpSampling  (None, 4, 4, 4, 256)     0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_transpose_5 (Conv3DT  (None, 4, 4, 4, 512)     16384000  \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 4, 4, 4, 512)     2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 4, 4, 4, 512)      0         \n",
            "                                                                 \n",
            " up_sampling3d_6 (UpSampling  (None, 8, 8, 8, 512)     0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_transpose_6 (Conv3DT  (None, 8, 8, 8, 256)     16384000  \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 8, 8, 8, 256)     1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 8, 8, 8, 256)      0         \n",
            "                                                                 \n",
            " up_sampling3d_7 (UpSampling  (None, 16, 16, 16, 256)  0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_transpose_7 (Conv3DT  (None, 16, 16, 16, 128)  4096000   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 16, 16, 16, 128)  512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 16, 16, 16, 128)   0         \n",
            "                                                                 \n",
            " up_sampling3d_8 (UpSampling  (None, 32, 32, 32, 128)  0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_transpose_8 (Conv3DT  (None, 32, 32, 32, 64)   1024000   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 32, 32, 32, 64)   256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 32, 32, 32, 64)    0         \n",
            "                                                                 \n",
            " up_sampling3d_9 (UpSampling  (None, 64, 64, 64, 64)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_transpose_9 (Conv3DT  (None, 64, 64, 64, 1)    8000      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 64, 64, 64, 1)     0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37,973,568\n",
            "Trainable params: 37,967,552\n",
            "Non-trainable params: 6,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tF5fTuKUvjU",
        "outputId": "4f5ff9ae-2fc1-4767-8860-f0fd0d638517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_4 (Conv3D)           (None, 32, 32, 32, 64)    8064      \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 32, 64)    0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32, 32, 32, 64)    0         \n",
            "                                                                 \n",
            " conv3d_5 (Conv3D)           (None, 16, 16, 16, 128)   1024128   \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 16, 128)   0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 16, 16, 16, 128)   0         \n",
            "                                                                 \n",
            " conv3d_6 (Conv3D)           (None, 8, 8, 8, 256)      4096256   \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 8, 8, 8, 256)      0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 8, 8, 8, 256)      0         \n",
            "                                                                 \n",
            " conv3d_7 (Conv3D)           (None, 4, 4, 4, 512)      16384512  \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 4, 4, 4, 512)      0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 4, 4, 4, 512)      0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 32769     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,545,729\n",
            "Trainable params: 21,545,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nKEPMQplSwWK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(sample_path, checkpoints_path, num_epochs=1000, batch_size=8, latent_dim=32, restore_D=None, restore_G=None, restore_epoch=0):\n",
        "    global discriminator\n",
        "    global generator\n",
        "\n",
        "    sample_epoch = 500\n",
        "    save_epoch = 500\n",
        "\n",
        "    dis_optim = RMSprop(lr=0.0002, decay=6e-8)\n",
        "    gen_optim = RMSprop(lr=0.0001, decay=3e-8)\n",
        "\n",
        "    if restore_D!=None:\n",
        "      discriminator=tf.keras.models.load_model(restore_D)\n",
        "\n",
        "    if restore_G!=None:\n",
        "      generator=tf.keras.models.load_model(restore_G)\n",
        "\n",
        "    generator.compile(optimizer=gen_optim)\n",
        "    discriminator.compile(optimizer=dis_optim)\n",
        "\n",
        "    dl, gl = [],[]\n",
        "    for epoch in range(restore_epoch, num_epochs):\n",
        "        #sample a random batch\n",
        "        idx = np.random.randint(len(training_data), size=batch_size)\n",
        "        real = training_data[idx]\n",
        "        real = real.reshape(real.shape+(1,))\n",
        "\n",
        "        noise = tf.random.normal([batch_size, latent_dim])\n",
        "        for i in range(3):\n",
        "\n",
        "          with tf.GradientTape() as disc_tape:\n",
        "        \n",
        "            generated_images = generator(noise, training=True)\n",
        "\n",
        "            real_output = discriminator(real, training=True)\n",
        "            fake_output = discriminator(generated_images, training=True)\n",
        "        \n",
        "            epsilon = tf.random.normal([batch_size, 1, 1, 1, 1], 0.0, 1.0)\n",
        "        \n",
        "            gp = gradient_penalty(real, generated_images, epsilon)\n",
        "        \n",
        "            disc_loss = discriminator_loss(real_output, fake_output, gp)\n",
        "\n",
        "    \n",
        "          gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "          dis_optim.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "        with tf.GradientTape() as gen_tape:\n",
        "          generated_images = generator(noise, training=True)\n",
        "          fake_output = discriminator(generated_images, training=True)\n",
        "          gen_loss = generator_loss(fake_output)\n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        gen_optim.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "        print('Training epoch {}/{}, d_loss: {},  g_loss: {}'.format(epoch+1, num_epochs, disc_loss, gen_loss))\n",
        "\n",
        "        # sampling\n",
        "        if epoch % sample_epoch == 0:\n",
        "            if not os.path.exists(sample_path):\n",
        "                os.makedirs(sample_path)\n",
        "            print('Sampling...')\n",
        "            sample_noise = np.random.uniform(-1.0, 1.0, size=[1, latent_dim]).astype(np.float64)\n",
        "            voxel_model = generator.predict(sample_noise, verbose=1)\n",
        "            voxel_model = voxel_model.reshape(voxel_model[0].shape[:-1])\n",
        "            voxel_model = np.rint(voxel_model)\n",
        "            try:\n",
        "              save_voxel(voxel_model, sample_path + f'/epoch_{epoch+1}.obj')\n",
        "            except Exception as ex:\n",
        "              print('Could not create voxel model... Continuing training')\n",
        "              print(ex)\n",
        "\n",
        "        # save weights\n",
        "        if epoch % save_epoch == 0:\n",
        "            if not os.path.exists(checkpoints_path):\n",
        "                os.makedirs(checkpoints_path)\n",
        "            generator.save(checkpoints_path + '/generator_epoch_' + str(epoch+1))\n",
        "            discriminator.save(checkpoints_path + '/discriminator_epoch_' + str(epoch+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NBvKIOCkc7Ix"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BCfx3_BmTHEq"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/training/samplings\n",
        "!mkdir -p /content/training/model_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v7M5bch9TH85",
        "outputId": "09517e01-65ec-4ea0-8348-5e8a6f24c661"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch 1/1000000, d_loss: -778.9308471679688,  g_loss: 7162.4765625\n",
            "Sampling...\n",
            "1/1 [==============================] - 1s 601ms/step\n",
            "model = VoxelModel(voxel_model)  \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Finding exterior voxels: 100%|██████████| 48/48 [00:00<00:00, 468.67it/s]\n",
            "Meshing: 100%|██████████| 540/540 [00:05<00:00, 100.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mesh = Mesh.fromVoxelModel(model)\n",
            "INFO:tensorflow:Assets written to: /content/training/model_checkpoints/generator_epoch_1/assets\n",
            "INFO:tensorflow:Assets written to: /content/training/model_checkpoints/discriminator_epoch_1/assets\n",
            "Training epoch 2/1000000, d_loss: -707.9207763671875,  g_loss: 1071.9080810546875\n",
            "Training epoch 3/1000000, d_loss: -547.8465576171875,  g_loss: 943.881103515625\n",
            "Training epoch 4/1000000, d_loss: -596.46728515625,  g_loss: 1101.9921875\n",
            "Training epoch 5/1000000, d_loss: -252.6448974609375,  g_loss: 387.1937255859375\n",
            "Training epoch 6/1000000, d_loss: -183.7472686767578,  g_loss: 300.0902099609375\n",
            "Training epoch 7/1000000, d_loss: -167.5020294189453,  g_loss: 270.99420166015625\n",
            "Training epoch 8/1000000, d_loss: -168.0524139404297,  g_loss: 252.30172729492188\n",
            "Training epoch 9/1000000, d_loss: -228.27256774902344,  g_loss: 370.7388916015625\n",
            "Training epoch 10/1000000, d_loss: -233.05300903320312,  g_loss: 337.6827392578125\n",
            "Training epoch 11/1000000, d_loss: -131.99697875976562,  g_loss: 194.57330322265625\n",
            "Training epoch 12/1000000, d_loss: -183.8457794189453,  g_loss: 292.89447021484375\n",
            "Training epoch 13/1000000, d_loss: -145.2141876220703,  g_loss: 205.71621704101562\n",
            "Training epoch 14/1000000, d_loss: -162.99899291992188,  g_loss: 247.22894287109375\n",
            "Training epoch 15/1000000, d_loss: -258.47332763671875,  g_loss: 430.92498779296875\n",
            "Training epoch 16/1000000, d_loss: 6353.26171875,  g_loss: 148.3423309326172\n",
            "Training epoch 17/1000000, d_loss: -16.175575256347656,  g_loss: 59.550575256347656\n",
            "Training epoch 18/1000000, d_loss: -45.16065979003906,  g_loss: 89.06475830078125\n",
            "Training epoch 19/1000000, d_loss: -45.82332229614258,  g_loss: 84.11688232421875\n",
            "Training epoch 20/1000000, d_loss: -43.680809020996094,  g_loss: 80.63207244873047\n",
            "Training epoch 21/1000000, d_loss: -40.881771087646484,  g_loss: 74.01380920410156\n",
            "Training epoch 22/1000000, d_loss: -29.98388671875,  g_loss: 64.90586853027344\n",
            "Training epoch 23/1000000, d_loss: -40.08087921142578,  g_loss: 67.16788482666016\n",
            "Training epoch 24/1000000, d_loss: -36.72145080566406,  g_loss: 56.707977294921875\n",
            "Training epoch 25/1000000, d_loss: -39.40150451660156,  g_loss: 61.078453063964844\n",
            "Training epoch 26/1000000, d_loss: -47.254638671875,  g_loss: 58.18840026855469\n",
            "Training epoch 27/1000000, d_loss: -12.876907348632812,  g_loss: 24.074710845947266\n",
            "Training epoch 28/1000000, d_loss: -90.08634948730469,  g_loss: 58.82799530029297\n",
            "Training epoch 29/1000000, d_loss: -137.023681640625,  g_loss: -13.575166702270508\n",
            "Training epoch 30/1000000, d_loss: -34.741336822509766,  g_loss: -8.740123748779297\n",
            "Training epoch 31/1000000, d_loss: -23.9114990234375,  g_loss: -19.916400909423828\n",
            "Training epoch 32/1000000, d_loss: -11.793159484863281,  g_loss: -28.172969818115234\n",
            "Training epoch 33/1000000, d_loss: -17.628591537475586,  g_loss: -29.98274040222168\n",
            "Training epoch 34/1000000, d_loss: -19.486915588378906,  g_loss: -27.37811851501465\n",
            "Training epoch 35/1000000, d_loss: -15.241190910339355,  g_loss: -28.428226470947266\n",
            "Training epoch 36/1000000, d_loss: -22.022045135498047,  g_loss: -20.830368041992188\n",
            "Training epoch 37/1000000, d_loss: -16.739025115966797,  g_loss: -27.142820358276367\n",
            "Training epoch 38/1000000, d_loss: -15.292834281921387,  g_loss: -26.96743392944336\n",
            "Training epoch 39/1000000, d_loss: -16.50963020324707,  g_loss: -22.64893913269043\n",
            "Training epoch 40/1000000, d_loss: -13.111167907714844,  g_loss: -31.427597045898438\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-dcef0e50aee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# checkpoints_path = '/content/gdrive/MyDrive/ivan/tree-from-scratch/model_checkpoints'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoints_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-e91f128676b9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(sample_path, checkpoints_path, num_epochs, batch_size, latent_dim, restore_D, restore_G, restore_epoch)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m           \u001b[0mgradients_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m           \u001b[0mdis_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "sample_path = '/content/training/samplings'\n",
        "checkpoints_path = '/content/training/model_checkpoints'\n",
        "\n",
        "train(sample_path, checkpoints_path, num_epochs=1000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-VLWfT7TUsZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Michelangelo ",
      "provenance": [],
      "background_execution": "on",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}